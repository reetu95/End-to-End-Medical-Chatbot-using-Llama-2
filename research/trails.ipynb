{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_API_ENV = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of my chunks: 5777\n",
      "Embedding dimension: 384\n",
      "Current index stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 5779}},\n",
      " 'total_vector_count': 5779,\n",
      " 'vector_type': 'dense'}\n",
      "✅ Embedding dimensions: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting to Pinecone: 100%|██████████| 58/58 [00:51<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final index stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 5779}},\n",
      " 'total_vector_count': 5779,\n",
      " 'vector_type': 'dense'}\n",
      "\n",
      "🔍 Test Query Results:\n",
      "\n",
      "🔹 Result 1:\n",
      "reaction. Allergic rhinitis is characterized by an itchy,\n",
      "runny nose, often with a scratchy or irritated throat due\n",
      "to post-nasal drip. Inflammation of the thin membrane\n",
      "covering the eye (allergic conjunctivitis) causes redness,\n",
      "irritation, and increased tearing in the eyes. Asthma caus-\n",
      "es wheezing...\n",
      "\n",
      "🔹 Result 2:\n",
      "reactions is triggered by harmless, everyday substances.\n",
      "This is the condition known as allergy, and the offend-\n",
      "ing substance is called an allergen. Common inhaled\n",
      "allergens include pollen, dust, and insect parts from tiny\n",
      "house mites. Common food allergens include nuts, fish,\n",
      "and milk.\n",
      "Allergic re...\n",
      "\n",
      "🔹 Result 3:\n",
      "to commonly encountered environmental substances.\n",
      "Purpose\n",
      "Allergy is a reaction of the immune system. Nor-\n",
      "mally, the immune system responds to foreign microor-\n",
      "ganisms and particles, like pollen or dust, by producing\n",
      "specific proteins called antibodies that are capable of\n",
      "binding to identifying mol...\n",
      "\n",
      "💬 Medical Chatbot Ready! (Type 'quit' to exit)\n",
      "\n",
      "✅ Response: Allergies are a condition where the body's immune system overreacts to harmless substances, such as pollen, dust, or certain foods. This overreaction can cause a range of symptoms, including itchy, runny noses, irritated eyes, and difficulty breathing.\n",
      "\n",
      "✅ Response: Asthma is caused by inhaling an allergen that sets off a chain of biochemical and tissue changes leading to airway inflammation, bronchoconstriction, and wheezing.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.llms import CTransformers\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "PINECONE_API_KEY = \"\"\n",
    "INDEX_NAME = \"\"\n",
    "REGION = \"us-east-1\"\n",
    "DIM = 384\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"PINECONE_ENVIRONMENT\"] = REGION\n",
    "\n",
    "# 1. Load PDF documents\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyMuPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "# 2. Split text into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, \n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "# 3. Load documents and create chunks\n",
    "extracted_data = load_pdf(\"data/\")\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(f\"Length of my chunks: {len(text_chunks)}\")\n",
    "\n",
    "# 4. Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "print(f\"Embedding dimension: {len(embeddings.embed_query('test'))}\")\n",
    "\n",
    "# 5. Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if INDEX_NAME not in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=REGION),\n",
    "    )\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(f\"Current index stats: {index.describe_index_stats()}\")\n",
    "\n",
    "# 6. Prepare and upsert vectors to Pinecone\n",
    "texts = [t.page_content for t in text_chunks]\n",
    "ids = [f\"doc-{i}\" for i in range(len(texts))]\n",
    "\n",
    "# Generate embeddings\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "print(f\"✅ Embedding dimensions: {len(vectors[0])}\")\n",
    "\n",
    "# Upsert in batches\n",
    "BATCH_SIZE = 100\n",
    "for i in tqdm(range(0, len(vectors), BATCH_SIZE), desc=\"Upserting to Pinecone\"):\n",
    "    batch = [\n",
    "        {\n",
    "            \"id\": ids[j],\n",
    "            \"values\": [float(x) for x in vectors[j]],\n",
    "            \"metadata\": {\"text\": texts[j]},\n",
    "        }\n",
    "        for j in range(i, min(i + BATCH_SIZE, len(vectors)))\n",
    "    ]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "print(f\"Final index stats: {index.describe_index_stats()}\")\n",
    "\n",
    "# 7. Create vector store from existing index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# 8. Test similarity search\n",
    "query = \"What are Allergies?\"\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\n🔍 Test Query Results:\")\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n🔹 Result {i+1}:\\n{d.page_content[:300]}...\")\n",
    "\n",
    "# 9. Setup the QA chain\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "# 10. Initialize LLM\n",
    "llm = CTransformers(\n",
    "    model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config={\n",
    "        'max_new_tokens': 512,\n",
    "        'temperature': 0.8\n",
    "    }\n",
    ")\n",
    "\n",
    "# 11. Create RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "\n",
    "# 12. Interactive loop\n",
    "print(\"\\n💬 Medical Chatbot Ready! (Type 'quit' to exit)\")\n",
    "while True:\n",
    "    user_input = input(\"\\nInput Prompt: \")\n",
    "    \n",
    "    if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    if not user_input.strip():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        result = qa.invoke({\"query\": user_input})\n",
    "        print(f\"\\n✅ Response: {result['result']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
