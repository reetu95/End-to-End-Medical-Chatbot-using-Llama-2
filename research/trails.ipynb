{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY: /opt/miniconda3/envs/mchatbot/bin/python\n",
      "Collecting pinecone==6.0.1\n",
      "  Using cached pinecone-6.0.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: langchain-pinecone==0.2.12 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pinecone==6.0.1) (2025.10.5)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone==6.0.1)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pinecone==6.0.1) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pinecone==6.0.1) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pinecone==6.0.1) (2.5.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-pinecone==0.2.12) (0.3.78)\n",
      "Requirement already satisfied: numpy>=1.26.4 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-pinecone==0.2.12) (1.26.4)\n",
      "Requirement already satisfied: langchain-openai>=0.3.11 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-pinecone==0.2.12) (0.3.35)\n",
      "Requirement already satisfied: httpx>=0.28.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-pinecone==0.2.12) (0.28.1)\n",
      "Requirement already satisfied: simsimd>=5.9.11 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-pinecone==0.2.12) (6.5.3)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (0.4.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (6.0.3)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (2.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpx>=0.28.0->langchain-pinecone==0.2.12) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpx>=0.28.0->langchain-pinecone==0.2.12) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpx>=0.28.0->langchain-pinecone==0.2.12) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.28.0->langchain-pinecone==0.2.12) (0.16.0)\n",
      "Requirement already satisfied: aiohttp>=3.9.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (3.13.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone==0.2.12) (1.22.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-openai>=0.3.11->langchain-pinecone==0.2.12) (2.2.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-openai>=0.3.11->langchain-pinecone==0.2.12) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone==0.2.12) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone==0.2.12) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone==0.2.12) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone==0.2.12) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from anyio->httpx>=0.28.0->langchain-pinecone==0.2.12) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai>=0.3.11->langchain-pinecone==0.2.12) (2025.9.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone==6.0.1) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone==0.2.12) (3.4.3)\n",
      "Using cached pinecone-6.0.1-py3-none-any.whl (421 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pinecone]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pinecone-6.0.1 pinecone-plugin-interface-0.0.7\n",
      "pinecone spec: ModuleSpec(name='pinecone', loader=<_frozen_importlib_external.SourceFileLoader object at 0x1076de800>, origin='/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/pinecone/__init__.py', submodule_search_locations=['/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/pinecone'])\n",
      "pinecone_plugins spec: None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "print(\"PY:\", sys.executable)  # this is the interpreter your notebook is using\n",
    "\n",
    "# install into THIS interpreter:\n",
    "import subprocess, shlex\n",
    "subprocess.check_call(shlex.split(f'{sys.executable} -m pip install -U \"pinecone==6.0.1\" \"langchain-pinecone==0.2.12\"'))\n",
    "\n",
    "# verify modules are visible to THIS interpreter\n",
    "print(\"pinecone spec:\", importlib.util.find_spec(\"pinecone\"))\n",
    "print(\"pinecone_plugins spec:\", importlib.util.find_spec(\"pinecone_plugins\"))  # should be None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pinecone version: 6.0.1\n",
      "✅ client OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pinecone\n",
    "print(\"✅ pinecone version:\", pinecone.__version__)\n",
    "\n",
    "pc = Pinecone(api_key=\"YOUR_API_KEY\")\n",
    "print(\"✅ client OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone \n",
    "import pinecone\n",
    "from langchain.document_loaders import PyMuPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mchatbot/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_4fq8QP_J7DL8gSFDwNiVrt6gzhHdFdaaTvpNNsmWxsgCijdh7QojxQVCzVYtSBoqABKNdZ\"\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyMuPDFLoader   # lowercase 'loader_cls'\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunks :  5777\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunks : \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download embedding model\n",
    "def download_hugging_face_embedding():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.45.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (4.57.0)\n",
      "Requirement already satisfied: sentence-transformers>=3.0.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (5.1.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (0.22.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (0.35.3)\n",
      "Requirement already satisfied: langchain-huggingface>=0.3.1 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (0.3.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from transformers>=4.45.0) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from transformers>=4.45.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from transformers>=4.45.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from transformers>=4.45.0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from transformers>=4.45.0) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from transformers>=4.45.0) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from transformers>=4.45.0) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from transformers>=4.45.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from huggingface-hub>=0.33.4) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from huggingface-hub>=0.33.4) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from huggingface-hub>=0.33.4) (1.1.10)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from sentence-transformers>=3.0.0) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from sentence-transformers>=3.0.0) (1.7.2)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from sentence-transformers>=3.0.0) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from sentence-transformers>=3.0.0) (11.3.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-huggingface>=0.3.1) (0.3.78)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (0.4.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (2.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from requests->transformers>=4.45.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from requests->transformers>=4.45.0) (2.5.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=3.0.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface>=0.3.1) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3.0.0) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=3.0.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=3.0.0) (3.6.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess, shlex\n",
    "py = sys.executable\n",
    "\n",
    "# install modern, mutually-compatible versions\n",
    "subprocess.check_call(shlex.split(f'{py} -m pip install -U \"transformers>=4.45.0\" \"sentence-transformers>=3.0.0\" \"tokenizers>=0.19.1\" \"huggingface-hub>=0.33.4\" \"langchain-huggingface>=0.3.1\"'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# embeddings = download_hugging_face_embedding()\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "print(len(embeddings.embed_query(\"test\")))  # 384\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result  query 384\n"
     ]
    }
   ],
   "source": [
    "#testing - Converting hello world into vectos and the dimentionality of that  vectore is 384\n",
    "result_query = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Result  query\", len(result_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_4fq8QP_J7DL8gSFDwNiVrt6gzhHdFdaaTvpNNsmWxsgCijdh7QojxQVCzVYtSBoqABKNdZ\"\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initializing the Pinecone\n",
    "# pinecone.init(api_key = PINECONE_API_KEY,\n",
    "#                environment = PINECONE_API_ENV)\n",
    "\n",
    "# index_name = \"medical-chatbot\"\n",
    "\n",
    "# #Creating Embeddings for Each of The Text Chunks & storing\n",
    "# docsearch=Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: ['medical-chatbot']\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "INDEX_NAME = \"medical-chatbot\"\n",
    "REGION = \"us-east-1\"                  # from your dashboard\n",
    "DIM = 384                             # all-MiniLM-L6-v2\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# create if missing\n",
    "if INDEX_NAME not in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=REGION),\n",
    "    )\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(\"Indexes:\", [i[\"name\"] for i in pc.list_indexes()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pinecone version: 6.0.1\n",
      "indexes: ['medical-chatbot']\n",
      "stats BEFORE: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 5779}},\n",
      " 'total_vector_count': 5779,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "import numpy as np\n",
    "\n",
    "print(\"pinecone version:\", __import__(\"pinecone\").__version__)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"indexes:\", [i[\"name\"] for i in pc.list_indexes()])\n",
    "\n",
    "index = pc.Index(\"medical-chatbot\")\n",
    "print(\"stats BEFORE:\", index.describe_index_stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding dimensions: {384}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:52<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 5779}},\n",
      " 'total_vector_count': 5779,\n",
      " 'vector_type': 'dense'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Prepare text chunks ---\n",
    "texts = [t.page_content for t in text_chunks]\n",
    "ids = [f\"doc-{i}\" for i in range(len(texts))]\n",
    "\n",
    "# --- Step 2: Generate embeddings ---\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "print(\"✅ Embedding dimensions:\", {len(v) for v in vectors})  # should show {384}\n",
    "\n",
    "# --- Step 3: Upsert into Pinecone ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "for i in tqdm(range(0, len(vectors), BATCH_SIZE)):\n",
    "    batch = [\n",
    "        {\n",
    "            \"id\": ids[j],\n",
    "            \"values\": [float(x) for x in vectors[j]],  # ensure pure floats\n",
    "            \"metadata\": {\"text\": texts[j]},\n",
    "        }\n",
    "        for j in range(i, min(i + BATCH_SIZE, len(vectors)))\n",
    "    ]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "# --- Step 4: Verify ---\n",
    "print(\"Index stats:\", index.describe_index_stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹Result 1:\n",
      "reaction. Allergic rhinitis is characterized by an itchy,\n",
      "runny nose, often with a scratchy or irritated throat due\n",
      "to post-nasal drip. Inflammation of the thin membrane\n",
      "covering the eye (allergic conjunctivitis) causes redness,\n",
      "irritation, and increased tearing in the eyes. Asthma caus-\n",
      "es wheezing ...\n",
      "\n",
      "🔹Result 2:\n",
      "reactions is triggered by harmless, everyday substances.\n",
      "This is the condition known as allergy, and the offend-\n",
      "ing substance is called an allergen. Common inhaled\n",
      "allergens include pollen, dust, and insect parts from tiny\n",
      "house mites. Common food allergens include nuts, fish,\n",
      "and milk.\n",
      "Allergic re ...\n",
      "\n",
      "🔹Result 3:\n",
      "to commonly encountered environmental substances.\n",
      "Purpose\n",
      "Allergy is a reaction of the immune system. Nor-\n",
      "mally, the immune system responds to foreign microor-\n",
      "ganisms and particles, like pollen or dust, by producing\n",
      "specific proteins called antibodies that are capable of\n",
      "binding to identifying mol ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Make sure these are set\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_4fq8QP_J7DL8gSFDwNiVrt6gzhHdFdaaTvpNNsmWxsgCijdh7QojxQVCzVYtSBoqABKNdZ\"\n",
    "os.environ[\"PINECONE_ENVIRONMENT\"] = \"us-east-1\"\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# connect to your existing Pinecone index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "query = \"What are Allergies?\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n🔹Result {i+1}:\\n{d.page_content[:300]} ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/t1m3g_0n54b7qq3hf262vsch0000gn/T/ipykernel_87869/4216317267.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result=qa({\"query\": user_input})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  There are no known allergens in the brain or nervous system. Therefore, it is unlikely that a person's allergy would cause an autopsy to be performed differently than normal. The protocol for performing an autopsy is standardized and follows strict guidelines to ensure accuracy and completeness of the examination.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/miniconda3/envs/mchatbot/lib/python3.10/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of my chunks: 5777\n",
      "Embedding dimension: 384\n",
      "Current index stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 5779}},\n",
      " 'total_vector_count': 5779,\n",
      " 'vector_type': 'dense'}\n",
      "✅ Embedding dimensions: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting to Pinecone: 100%|██████████| 58/58 [00:51<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final index stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 5779}},\n",
      " 'total_vector_count': 5779,\n",
      " 'vector_type': 'dense'}\n",
      "\n",
      "🔍 Test Query Results:\n",
      "\n",
      "🔹 Result 1:\n",
      "reaction. Allergic rhinitis is characterized by an itchy,\n",
      "runny nose, often with a scratchy or irritated throat due\n",
      "to post-nasal drip. Inflammation of the thin membrane\n",
      "covering the eye (allergic conjunctivitis) causes redness,\n",
      "irritation, and increased tearing in the eyes. Asthma caus-\n",
      "es wheezing...\n",
      "\n",
      "🔹 Result 2:\n",
      "reactions is triggered by harmless, everyday substances.\n",
      "This is the condition known as allergy, and the offend-\n",
      "ing substance is called an allergen. Common inhaled\n",
      "allergens include pollen, dust, and insect parts from tiny\n",
      "house mites. Common food allergens include nuts, fish,\n",
      "and milk.\n",
      "Allergic re...\n",
      "\n",
      "🔹 Result 3:\n",
      "to commonly encountered environmental substances.\n",
      "Purpose\n",
      "Allergy is a reaction of the immune system. Nor-\n",
      "mally, the immune system responds to foreign microor-\n",
      "ganisms and particles, like pollen or dust, by producing\n",
      "specific proteins called antibodies that are capable of\n",
      "binding to identifying mol...\n",
      "\n",
      "💬 Medical Chatbot Ready! (Type 'quit' to exit)\n",
      "\n",
      "✅ Response: Allergies are a condition where the body's immune system overreacts to harmless substances, such as pollen, dust, or certain foods. This overreaction can cause a range of symptoms, including itchy, runny noses, irritated eyes, and difficulty breathing.\n",
      "\n",
      "✅ Response: Asthma is caused by inhaling an allergen that sets off a chain of biochemical and tissue changes leading to airway inflammation, bronchoconstriction, and wheezing.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.llms import CTransformers\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "PINECONE_API_KEY = \"pcsk_4fq8QP_J7DL8gSFDwNiVrt6gzhHdFdaaTvpNNsmWxsgCijdh7QojxQVCzVYtSBoqABKNdZ\"\n",
    "INDEX_NAME = \"medical-chatbot\"\n",
    "REGION = \"us-east-1\"\n",
    "DIM = 384\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"PINECONE_ENVIRONMENT\"] = REGION\n",
    "\n",
    "# 1. Load PDF documents\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyMuPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "# 2. Split text into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, \n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "# 3. Load documents and create chunks\n",
    "extracted_data = load_pdf(\"data/\")\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(f\"Length of my chunks: {len(text_chunks)}\")\n",
    "\n",
    "# 4. Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "print(f\"Embedding dimension: {len(embeddings.embed_query('test'))}\")\n",
    "\n",
    "# 5. Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if INDEX_NAME not in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=REGION),\n",
    "    )\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(f\"Current index stats: {index.describe_index_stats()}\")\n",
    "\n",
    "# 6. Prepare and upsert vectors to Pinecone\n",
    "texts = [t.page_content for t in text_chunks]\n",
    "ids = [f\"doc-{i}\" for i in range(len(texts))]\n",
    "\n",
    "# Generate embeddings\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "print(f\"✅ Embedding dimensions: {len(vectors[0])}\")\n",
    "\n",
    "# Upsert in batches\n",
    "BATCH_SIZE = 100\n",
    "for i in tqdm(range(0, len(vectors), BATCH_SIZE), desc=\"Upserting to Pinecone\"):\n",
    "    batch = [\n",
    "        {\n",
    "            \"id\": ids[j],\n",
    "            \"values\": [float(x) for x in vectors[j]],\n",
    "            \"metadata\": {\"text\": texts[j]},\n",
    "        }\n",
    "        for j in range(i, min(i + BATCH_SIZE, len(vectors)))\n",
    "    ]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "print(f\"Final index stats: {index.describe_index_stats()}\")\n",
    "\n",
    "# 7. Create vector store from existing index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# 8. Test similarity search\n",
    "query = \"What are Allergies?\"\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\n🔍 Test Query Results:\")\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n🔹 Result {i+1}:\\n{d.page_content[:300]}...\")\n",
    "\n",
    "# 9. Setup the QA chain\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "# 10. Initialize LLM\n",
    "llm = CTransformers(\n",
    "    model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config={\n",
    "        'max_new_tokens': 512,\n",
    "        'temperature': 0.8\n",
    "    }\n",
    ")\n",
    "\n",
    "# 11. Create RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "\n",
    "# 12. Interactive loop\n",
    "print(\"\\n💬 Medical Chatbot Ready! (Type 'quit' to exit)\")\n",
    "while True:\n",
    "    user_input = input(\"\\nInput Prompt: \")\n",
    "    \n",
    "    if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    if not user_input.strip():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        result = qa.invoke({\"query\": user_input})\n",
    "        print(f\"\\n✅ Response: {result['result']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
